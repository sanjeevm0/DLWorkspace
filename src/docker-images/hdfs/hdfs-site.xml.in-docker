<configuration>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>{{cnf["dfs"]["data"]}}</value>
        <description>Comma separated list of paths on the local filesystem of a DataNode where it should store its blocks.</description>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file://{{cnf["namenode"]["localdata"]}}</value>
        <description>Path on the local filesystem where the NameNode stores the namespace and transaction logs persistently. shared at file://{{cnf["namenode"]["data"]}}</description>
    </property>
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>ha.zookeeper.quorum</name>
        <value>{{cnf["zks"]["nodes"]}}</value>
    </property>
    <property>
      <name>dfs.nameservices</name>
      <value>{{cnf["hdfs_cluster_name"]}}</value>
    </property>
    <property>
      <name>dfs.ha.namenodes.{{cnf["hdfs_cluster_name"]}}</name>
      <value>nn1,nn2</value>
    </property>
    <property>
      <name>dfs.namenode.rpc-address.{{cnf["hdfs_cluster_name"]}}.nn1</name>
      <value>{{cnf["namenode"]["namenode1"]}}:8020</value>
    </property>
    <property>
      <name>dfs.namenode.rpc-address.{{cnf["hdfs_cluster_name"]}}.nn2</name>
      <value>{{cnf["namenode"]["namenode2"]}}:8020</value>
    </property>
    <property>
      <name>dfs.namenode.http-address.{{cnf["hdfs_cluster_name"]}}.nn1</name>
      <value>{{cnf["namenode"]["namenode1"]}}:50070</value>
    </property>
    <property>
      <name>dfs.namenode.http-address.CLUSTER_NAME.nn2</name>
      <value>{{cnf["namenode"]["namenode1"]}}:50070</value>
    </property>
    <property>
      <name>dfs.namenode.shared.edits.dir</name>
      <value>qjournal://{{cnf["journalnode"]["nodes"]}}/{{cnf["hdfs_cluster_name"]}}</value>
    </property>
    <property>
      <name>dfs.client.failover.proxy.provider.mycluster</name>
      <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
      <name>dfs.ha.fencing.methods</name>
      <value>shell(/bin/true)</value>
    </property>
    <property>
      <name>dfs.journalnode.edits.dir</name>
      <value>{{cnf["journalnode"]["data"]}}</value>
    </property>
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>
</configuration>